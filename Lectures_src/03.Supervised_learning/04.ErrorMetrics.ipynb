{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science and Machine Learning\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img width=\"699\" alt=\"image\" src=\"https://user-images.githubusercontent.com/49638680/159042792-8510fbd1-c4ac-4a48-8320-bc6c1a49cdae.png\">\n",
    "</p>\n",
    "\n",
    "---\n",
    "\n",
    "## Performance metrics\n",
    "\n",
    "We are now to a crucial question.\n",
    "\n",
    "> To what extent can we trust our trained models?\n",
    "\n",
    "Actually the question is even more basic: How can we measure model performances?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "\n",
    "The _Accuracy_ is the most simple metric one can think about: it is the _ratio_ between the number of correctly classified objects over the total ones.\n",
    "\n",
    "$$\\mathrm{Accuracy} := \\frac{1}{N}\\sum_i \\vert y_i - \\hat{y}_i \\vert\\, . $$\n",
    "\n",
    "\n",
    "\n",
    "### Precision, Recall\n",
    "\n",
    "\n",
    "\n",
    "#### PRC Curve\n",
    "\n",
    "<p align=\"center\"> \n",
    "    <img width=\"607\" alt=\"ROC Curve\" src=\"https://user-images.githubusercontent.com/26833433/76019078-0a79fb00-5ed6-11ea-8b5b-5697bbbd7e7e.png\">\n",
    "</p>\n",
    "\n",
    "### $F_\\beta$-Score\n",
    "\n",
    "#### Specificity\n",
    "\n",
    "### ROC Curve\n",
    "\n",
    "<p align=\"center\"> \n",
    "    <img width=\"607\" alt=\"ROC Curve\" src=\"https://user-images.githubusercontent.com/49638680/160185181-8f7d7c2b-3440-422d-86b7-dd0c9bd61393.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
