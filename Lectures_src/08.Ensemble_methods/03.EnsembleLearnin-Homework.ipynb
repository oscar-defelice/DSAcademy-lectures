{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science and Machine Learning\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img width=\"699\" alt=\"image\" src=\"https://user-images.githubusercontent.com/49638680/159042792-8510fbd1-c4ac-4a48-8320-bc6c1a49cdae.png\">\n",
    "</p>\n",
    "\n",
    "---\n",
    "\n",
    "### Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_blobs, load_wine\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from utils.plottings import plot_learning_curve\n",
    "from utils.helpers_Garden import visualize_tree, plot_tree_interactive, randomized_tree_interactive, visualize_classifier\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "plt.rcParams['figure.figsize'] = (25.0, 10.0)\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Classify the digit dataset with a decision tree such that your classifier is in overfit.\n",
    "\n",
    "1. Show that actually the classifier overfits data.\n",
    "2. Play with hyperparameters in order to improve the model performances on test set.\n",
    "3. Apply ensemble methods (Random Forest or the explicit bagging classifier) to show how these reduce overfit and increase test accuracy.\n",
    "\n",
    "__NOTE__: you should get a final accuracy above the $95\\%$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Predict the churn rate with the xgboost classifier.\n",
    "\n",
    "Here, you will be working with churn data. This dataset contains imaginary data from a ride-sharing app with user behaviors over their first month of app usage in a set of imaginary cities as well as whether they used the service 5 months after sign-up.\n",
    "\n",
    "Download the dataset [here](https://raw.githubusercontent.com/goodboychan/goodboychan.github.io/main/_notebooks/dataset/churn_data.csv)\n",
    "\n",
    "1. Write pipelines for preprocessing\n",
    "2. Perform the right choices for hyperparameters.\n",
    "3. Verify that your model does not overfits data. Measure the right metrics to justify your answers.\n",
    "\n",
    "__NOTE__: you should get a final accuracy above the $75\\%$.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('lectures')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "344cc1eeed8544eb3655402a89f8b06dbf0ee0c5373119cdc275e8f730c3c713"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
